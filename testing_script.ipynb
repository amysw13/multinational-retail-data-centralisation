{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing script\n",
    "\n",
    "Script for testing out classes created for Multinational Retail Data Centralisation project. \n",
    "\n",
    "\n",
    "## Load in modules of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database_utils\n",
    "import data_extraction\n",
    "import data_cleaning\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = database_utils.DatabaseConnector()\n",
    "extractor = data_extraction.DataExtractor()\n",
    "cleaning = data_cleaning.DataCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilise class methods to connect to AWS RDS database and retrieve list of table names from postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract table data into a panda dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df = extractor.read_rds_table('legacy_users', engine)\n",
    "rds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning user data testing\n",
    "\n",
    "This is testing scripts for cleaning up phone_numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone number cleaning\n",
    "\n",
    "This is a bit more complicated than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df['phone_number'] = np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])\n",
    "\n",
    "isd_code_map = { \"GB\": \"+44\", \"DE\": \"+49\", \"US\": \"+1\" }\n",
    "\n",
    "def correct_phone_number(row):\n",
    "  import re\n",
    "  # Remove special chars other than digits, `+` and letters used for extension e.g. `x`, `ext` (following keeps all alphabets).\n",
    "  result = re.sub(\"[^A-Za-z\\d\\+]\", \"\", row[\"phone_number\"])\n",
    "  \n",
    "  # Prefix ISD code by matching country code.\n",
    "  if not result.startswith(isd_code_map[row[\"country_code\"]]):\n",
    "    result = isd_code_map[row[\"country_code\"]] + result\n",
    "\n",
    "  # Remove `0` that follows ISD code.\n",
    "  if result.startswith(isd_code_map[row[\"country_code\"]] + \"0\"):\n",
    "    result = result.replace(isd_code_map[row[\"country_code\"]] + \"0\", isd_code_map[row[\"country_code\"]])\n",
    "  return result\n",
    "\n",
    "rds_df[\"Corrected Phone Number\"] = rds_df.apply(correct_phone_number, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex_expression = '^(?:(?:\\(?(?:0(?:0|11)\\)?[\\s-]?\\(?|\\+)44\\)?[\\s-]?(?:\\(?0\\)?[\\s-]?)?)|(?:\\(?0))(?:(?:\\d{5}\\)?[\\s-]?\\d{4,5})|(?:\\d{4}\\)?[\\s-]?(?:\\d{5}|\\d{3}[\\s-]?\\d{3}))|(?:\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4})|(?:\\d{2}\\)?[\\s-]?\\d{4}[\\s-]?\\d{4}))(?:[\\s-]?(?:x|ext\\.?|\\#)\\d{3,4})?$' #Our regular expression to match\n",
    "#rds_df['phone_number'] = np.where(rds_df['country'] == 'United Kingdom', rds_df['phone_number'].str.match(regex_expression), np.nan)\n",
    "\n",
    "np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up of User data using pandas. \n",
    "These test methods will be finalised and entered into the data_cleaning class methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check address formatting issues - seems there could be issues with /n - regrex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rds_df = cleaning.clean_user_data(rds_df)\n",
    "\n",
    "print(type(clean_rds_df))\n",
    "print(clean_rds_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload cleaned up data to sales_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_rds_df, 'dim_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Details data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data\n",
    "card_df = extractor.retrieve_pdf_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning card details data\n",
    "cleaning = data_cleaning.DataCleaning()\n",
    "clean_card_df = cleaning.clean_card_data(card_df)\n",
    "clean_card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_card_df, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store details\n",
    "\n",
    "endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "header = {'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stores = extractor.list_number_of_stores('https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores',{'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df2 = extractor.retrieve_stores_data(num_stores,'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = stores_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cleaning methods\n",
    "clean_stores_df = cleaning.called_clean_store_data(stores_df)\n",
    "clean_stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_stores_df, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning store details dataframe\n",
    "\n",
    "Running through interactively store dataframe cleaning and applying appropriate methods back into class methods. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- delete lat column\n",
    "- continent - Spelling/formatting 'eeEurope'\n",
    "- opening_data - formatting to datetime\n",
    "- address - formatting\n",
    "- longitude - consistent formatting\n",
    "- remove rows of wrong/NULL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stores_df.to_string())\n",
    "stores_df.info() #450\n",
    "stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - delete/drop lat column\n",
    "# - continent - Spelling/formatting 'eeEurope'\n",
    "# - opening_data - formatting to datetime\n",
    "# - address - formatting\n",
    "# - longitude - consistent formatting???\n",
    "# - remove rows of wrong/ NULL data /\n",
    "stores_df = stores_df.drop('lat', axis=1) #remember to add axis = 1 for dropping column\n",
    "stores_df['continent'] = stores_df['continent'].replace(\"eeEurope\", \"Europe\")\n",
    "stores_df['address'] = stores_df['address'].str.replace('\\n', ' ')\n",
    "stores_df['address'] = stores_df['address'].str.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.info() \n",
    "stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df['staff_numbers'] = pd.to_numeric(stores_df['staff_numbers'], errors='coerce')\n",
    "stores_df['longitude'] = pd.to_numeric(stores_df['longitude'], errors='coerce')\n",
    "stores_df['latitude'] = pd.to_numeric(stores_df['latitude'], errors='coerce')\n",
    "stores_df['opening_date'] = pd.to_datetime(stores_df['opening_date'],  format= 'mixed', errors='coerce')\n",
    "stores_df.info() \n",
    "stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = stores_df.replace('NULL', np.NaN)\n",
    "stores_df = stores_df.dropna()\n",
    "stores_df['staff_numbers'] = stores_df['staff_numbers'].astype('int')\n",
    "stores_df.info() #435\n",
    "stores_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product details\n",
    "\n",
    "Milestone 2 - Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = extractor.extract_from_s3('s3://data-handling-public/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning product dataframe \n",
    "\n",
    "1. If you check the weight column in the DataFrame the weights all have different units.\n",
    "Convert them all to a decimal value representing their weight in kg. Use a 1:1 ratio of ml to g as a rough estimate for the rows containing ml.\n",
    "Develop the method to clean up the weight column and remove all excess characters then represent the weights as a float.\n",
    "\n",
    "2. Clean up any other erroneous values\n",
    "\n",
    "3. Once complete insert the data into the sales_data database using your upload_to_db method storing it in a table named dim_products.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_weight = cleaning.convert_product_weights(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_product_df = cleaning.clean_products_data(product_df_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_product_df, 'dim_products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order data\n",
    "\n",
    "Create a method in DataCleaning called clean_orders_data which will clean the orders table data.\n",
    "\n",
    "You should remove the columns, first_name, last_name and 1 to have the table in the correct form before uploading to the database.\n",
    "\n",
    "You will see that the orders data contains column headers which are the same in other tables.\n",
    "\n",
    "This table will act as the source of truth for your sales data and will be at the center of your star based database schema.\n",
    "\n",
    "\n",
    "\n",
    "Once cleaned upload using the upload_to_db method and store in a table called orders_table,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = extractor.read_rds_table('orders_table', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amy_multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
