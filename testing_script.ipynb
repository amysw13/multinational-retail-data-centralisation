{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing script\n",
    "\n",
    "Script for testing out classes created for Multinational Retail Data Centralisation project. \n",
    "\n",
    "**Note** Update docstrings for classes and methods accordingly as functionality develops. \n",
    "\n",
    "\n",
    "## Load in modules of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database_utils\n",
    "import data_extraction\n",
    "import data_cleaning\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = database_utils.DatabaseConnector()\n",
    "extractor = data_extraction.DataExtractor()\n",
    "cleaning = data_cleaning.DataCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilise class methods to connect to AWS RDS database and retrieve list of table names from postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract table data into a panda dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df = extractor.read_rds_table('legacy_users', engine)\n",
    "rds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning user data testing\n",
    "\n",
    "This is testing scripts for cleaning up phone_numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone number cleaning\n",
    "\n",
    "This is a bit more complicated than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df['phone_number'] = np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])\n",
    "\n",
    "isd_code_map = { \"GB\": \"+44\", \"DE\": \"+49\", \"US\": \"+1\" }\n",
    "\n",
    "def correct_phone_number(row):\n",
    "  import re\n",
    "  # Remove special chars other than digits, `+` and letters used for extension e.g. `x`, `ext` (following keeps all alphabets).\n",
    "  result = re.sub(\"[^A-Za-z\\d\\+]\", \"\", row[\"phone_number\"])\n",
    "  \n",
    "  # Prefix ISD code by matching country code.\n",
    "  if not result.startswith(isd_code_map[row[\"country_code\"]]):\n",
    "    result = isd_code_map[row[\"country_code\"]] + result\n",
    "\n",
    "  # Remove `0` that follows ISD code.\n",
    "  if result.startswith(isd_code_map[row[\"country_code\"]] + \"0\"):\n",
    "    result = result.replace(isd_code_map[row[\"country_code\"]] + \"0\", isd_code_map[row[\"country_code\"]])\n",
    "  return result\n",
    "\n",
    "rds_df[\"Corrected Phone Number\"] = rds_df.apply(correct_phone_number, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex_expression = '^(?:(?:\\(?(?:0(?:0|11)\\)?[\\s-]?\\(?|\\+)44\\)?[\\s-]?(?:\\(?0\\)?[\\s-]?)?)|(?:\\(?0))(?:(?:\\d{5}\\)?[\\s-]?\\d{4,5})|(?:\\d{4}\\)?[\\s-]?(?:\\d{5}|\\d{3}[\\s-]?\\d{3}))|(?:\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4})|(?:\\d{2}\\)?[\\s-]?\\d{4}[\\s-]?\\d{4}))(?:[\\s-]?(?:x|ext\\.?|\\#)\\d{3,4})?$' #Our regular expression to match\n",
    "#rds_df['phone_number'] = np.where(rds_df['country'] == 'United Kingdom', rds_df['phone_number'].str.match(regex_expression), np.nan)\n",
    "\n",
    "np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up of User data using pandas. \n",
    "These test methods will be finalised and entered into the data_cleaning class methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check address formatting issues - seems there could be issues with /n - regrex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rds_df = cleaning.clean_user_data(rds_df)\n",
    "\n",
    "print(type(clean_rds_df))\n",
    "print(clean_rds_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload cleaned up data to sales_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_rds_df, 'dim_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Details data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data\n",
    "card_df = extractor.retrieve_pdf_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning card details data\n",
    "cleaning = data_cleaning.DataCleaning()\n",
    "clean_card_df = cleaning.clean_card_data(card_df)\n",
    "clean_card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_card_df, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store details\n",
    "\n",
    "endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "header = {'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stores = extractor.list_number_of_stores('https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores',{'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df2 = extractor.retrieve_stores_data(num_stores,'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = stores_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cleaning methods\n",
    "clean_stores_df = cleaning.called_clean_store_data(stores_df)\n",
    "clean_stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_stores_df, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product details\n",
    "\n",
    "Milestone 2 - Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = extractor.extract_from_s3('s3://data-handling-public/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_weight = cleaning.convert_product_weights(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_product_df = cleaning.clean_products_data(product_df_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_product_df, 'dim_products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order data\n",
    "\n",
    "Create a method in DataCleaning called clean_orders_data which will clean the orders table data.\n",
    "\n",
    "You should remove the columns, first_name, last_name and 1 to have the table in the correct form before uploading to the database.\n",
    "\n",
    "You will see that the orders data contains column headers which are the same in other tables.\n",
    "\n",
    "This table will act as the source of truth for your sales data and will be at the center of your star based database schema.\n",
    "\n",
    "\n",
    "\n",
    "Once cleaned upload using the upload_to_db method and store in a table called orders_table,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = extractor.read_rds_table('orders_table', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_orders_df = cleaning.clean_orders_data(orders_df)\n",
    "\n",
    "#note had to delete level_0 column as was causing duplicate col error, which couldn't find resolution\n",
    "clean_orders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_orders_df, 'orders_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>time_period</th>\n",
       "      <th>date_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22:00:06</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>19</td>\n",
       "      <td>Evening</td>\n",
       "      <td>3b7ca996-37f9-433f-b6d0-ce8391b615ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22:44:06</td>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>10</td>\n",
       "      <td>Evening</td>\n",
       "      <td>adc86836-6c35-49ca-bb0d-65b6507a00fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:05:37</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>15</td>\n",
       "      <td>Morning</td>\n",
       "      <td>5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17:29:27</td>\n",
       "      <td>11</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>Midday</td>\n",
       "      <td>1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22:40:33</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>31</td>\n",
       "      <td>Evening</td>\n",
       "      <td>dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp month  year day time_period                             date_uuid\n",
       "0  22:00:06     9  2012  19     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad\n",
       "1  22:44:06     2  1997  10     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa\n",
       "2  10:05:37     4  1994  15     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31\n",
       "3  17:29:27    11  2001   6      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8\n",
       "4  22:40:33    12  2015  31     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = extractor.extract_from_s3('https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json')\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_event_df = cleaning.clean_events_data(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_event_df, 'dim_date_times')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amy_multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
