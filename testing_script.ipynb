{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing script\n",
    "\n",
    "Script for testing out classes created for Multinational Retail Data Centralisation project. \n",
    "\n",
    "**Note** Update docstrings for classes and methods accordingly as functionality develops. \n",
    "\n",
    "\n",
    "## Load in modules of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database_utils\n",
    "import data_extraction\n",
    "import data_cleaning\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = database_utils.DatabaseConnector()\n",
    "extractor = data_extraction.DataExtractor()\n",
    "cleaning = data_cleaning.DataCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilise class methods to connect to AWS RDS database and retrieve list of table names from postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract table data into a panda dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df = extractor.read_rds_table('legacy_users', engine)\n",
    "rds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning user data testing\n",
    "\n",
    "This is testing scripts for cleaning up phone_numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone number cleaning\n",
    "\n",
    "This is a bit more complicated than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_df['phone_number'] = np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])\n",
    "\n",
    "isd_code_map = { \"GB\": \"+44\", \"DE\": \"+49\", \"US\": \"+1\" }\n",
    "\n",
    "def correct_phone_number(row):\n",
    "  import re\n",
    "  # Remove special chars other than digits, `+` and letters used for extension e.g. `x`, `ext` (following keeps all alphabets).\n",
    "  result = re.sub(\"[^A-Za-z\\d\\+]\", \"\", row[\"phone_number\"])\n",
    "  \n",
    "  # Prefix ISD code by matching country code.\n",
    "  if not result.startswith(isd_code_map[row[\"country_code\"]]):\n",
    "    result = isd_code_map[row[\"country_code\"]] + result\n",
    "\n",
    "  # Remove `0` that follows ISD code.\n",
    "  if result.startswith(isd_code_map[row[\"country_code\"]] + \"0\"):\n",
    "    result = result.replace(isd_code_map[row[\"country_code\"]] + \"0\", isd_code_map[row[\"country_code\"]])\n",
    "  return result\n",
    "\n",
    "rds_df[\"Corrected Phone Number\"] = rds_df.apply(correct_phone_number, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex_expression = '^(?:(?:\\(?(?:0(?:0|11)\\)?[\\s-]?\\(?|\\+)44\\)?[\\s-]?(?:\\(?0\\)?[\\s-]?)?)|(?:\\(?0))(?:(?:\\d{5}\\)?[\\s-]?\\d{4,5})|(?:\\d{4}\\)?[\\s-]?(?:\\d{5}|\\d{3}[\\s-]?\\d{3}))|(?:\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4})|(?:\\d{2}\\)?[\\s-]?\\d{4}[\\s-]?\\d{4}))(?:[\\s-]?(?:x|ext\\.?|\\#)\\d{3,4})?$' #Our regular expression to match\n",
    "#rds_df['phone_number'] = np.where(rds_df['country'] == 'United Kingdom', rds_df['phone_number'].str.match(regex_expression), np.nan)\n",
    "\n",
    "np.where(rds_df['phone_number'].str.startswith('A-Z|a-z'), np.nan, rds_df['phone_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up of User data using pandas. \n",
    "These test methods will be finalised and entered into the data_cleaning class methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check address formatting issues - seems there could be issues with /n - regrex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rds_df = cleaning.clean_user_data(rds_df)\n",
    "\n",
    "print(type(clean_rds_df))\n",
    "print(clean_rds_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload cleaned up data to sales_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_rds_df, 'dim_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Details data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data\n",
    "card_df = extractor.retrieve_pdf_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning card details data\n",
    "cleaning = data_cleaning.DataCleaning()\n",
    "clean_card_df = cleaning.clean_card_data(card_df)\n",
    "clean_card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_card_df, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store details\n",
    "\n",
    "endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "header = {'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stores = extractor.list_number_of_stores('https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores',{'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df2 = extractor.retrieve_stores_data(num_stores,'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = stores_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cleaning methods\n",
    "clean_stores_df = cleaning.called_clean_store_data(stores_df)\n",
    "clean_stores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload cleaned data to local database\n",
    "connector.upload_to_db(clean_stores_df, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product details\n",
    "\n",
    "Milestone 2 - Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = extractor.extract_from_s3('s3://data-handling-public/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_weight = cleaning.convert_product_weights(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_product_df = cleaning.clean_products_data(product_df_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_product_df, 'dim_products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order data\n",
    "\n",
    "Create a method in DataCleaning called clean_orders_data which will clean the orders table data.\n",
    "\n",
    "You should remove the columns, first_name, last_name and 1 to have the table in the correct form before uploading to the database.\n",
    "\n",
    "You will see that the orders data contains column headers which are the same in other tables.\n",
    "\n",
    "This table will act as the source of truth for your sales data and will be at the center of your star based database schema.\n",
    "\n",
    "\n",
    "\n",
    "Once cleaned upload using the upload_to_db method and store in a table called orders_table,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = connector.read_db_creds()\n",
    "engine = connector.init_db_engine()\n",
    "db_list = connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = extractor.read_rds_table('orders_table', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120123 entries, 0 to 120122\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   index             120123 non-null  int64 \n",
      " 1   date_uuid         120123 non-null  object\n",
      " 2   user_uuid         120123 non-null  object\n",
      " 3   card_number       120123 non-null  int64 \n",
      " 4   store_code        120123 non-null  object\n",
      " 5   product_code      120123 non-null  object\n",
      " 6   product_quantity  120123 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_orders_df = cleaning.clean_orders_data(orders_df)\n",
    "\n",
    "#note had to delete level_0 column as was causing duplicate col error, which couldn't find resolution\n",
    "clean_orders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload_to_db(clean_orders_df, 'orders_table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amy_multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
